# تشخیص داده‌های پرت در الگوریتم K-Means

## معرفی
الگوریتم **K-Means** یکی از روش‌های خوشه‌بندی بدون ناظر است و به‌صورت مستقیم برای شناسایی داده‌های پرت (Outlier) طراحی نشده است.  
با این حال، با تحلیل نتایج خروجی این الگوریتم می‌توان داده‌های پرت احتمالی را شناسایی کرد.

---

## روش‌های شناسایی داده‌های پرت

### ۱. فاصله از مرکز خوشه (Centroid)
پس از اجرای الگوریتم K-Means، فاصله هر داده تا مرکز خوشه مربوط به خود محاسبه می‌شود.

- داده‌هایی که فاصله آن‌ها به‌طور غیرعادی از مرکز خوشه زیاد است، می‌توانند داده پرت محسوب شوند.
- آستانه‌های متداول:
  - میانگین فاصله‌ها + ۲ یا ۳ برابر انحراف معیار
  - بزرگ‌تر از صدک ۹۵ فاصله‌ها

**مزایا:** ساده و پرکاربرد  
**معایب:** وابسته به انتخاب آستانه مناسب

---

### ۲. شناسایی خوشه‌های کوچک
در برخی موارد، K-Means خوشه‌هایی با تعداد اعضای بسیار کم ایجاد می‌کند.

- خوشه‌هایی با تعداد نقاط کم (مثلاً کمتر از ۵٪ کل داده‌ها) می‌توانند نماینده داده‌های پرت باشند.
- تمام نقاط این خوشه‌ها به‌عنوان داده پرت در نظر گرفته می‌شوند.

**مزایا:** مناسب برای داده‌های کاملاً جدا  
**معایب:** وابسته به مقدار انتخاب‌شده برای k

---

### ۳. سهم داده در خطای خوشه‌بندی (SSE یا Inertia)
هر داده سهمی در مقدار کل **مجموع مربعات خطا (SSE)** دارد.

- داده‌هایی که سهم زیادی در افزایش SSE دارند، می‌توانند داده پرت باشند.
- حذف این داده‌ها معمولاً باعث کاهش قابل‌توجه مقدار Inertia می‌شود.

**مزایا:** بررسی تأثیر کلی داده پرت  
**معایب:** تشخیص دقیق داده پرت به‌صورت نقطه‌ای دشوار است

---

### ۴. مقایسه فاصله درون‌خوشه‌ای و بین‌خوشه‌ای
برای هر داده:
- فاصله تا مرکز خوشه خودش
- فاصله تا نزدیک‌ترین مرکز خوشه دیگر

اگر هر دو فاصله زیاد باشند، آن داده می‌تواند پرت محسوب شود.  
این ایده به مفهوم **ضریب سیلوئت (Silhouette Score)** نزدیک است.

---

### ۵. بررسی پایداری خوشه‌بندی
با اجرای چندباره الگوریتم K-Means با مقداردهی اولیه یا مقادیر مختلف k:

- داده‌هایی که مرتب خوشه خود را تغییر می‌دهند
- داده‌هایی که همواره فاصله زیادی از مراکز خوشه دارند

به‌عنوان داده‌های پرت بالقوه شناسایی می‌شوند.

---

## جمع‌بندی
الگوریتم K-Means ابزار مستقیمی برای تشخیص داده پرت نیست، اما با استفاده از معیارهای زیر می‌توان داده‌های پرت را شناسایی کرد:

- فاصله از مرکز خوشه  
- عضویت در خوشه‌های کوچک  
- سهم زیاد در مقدار SSE  
- ناپایداری در خوشه‌بندی  

در مسائل عملی، معمولاً K-Means در کنار روش‌هایی مانند **DBSCAN** و **Isolation Forest** استفاده می‌شود.

---

## منابع
- MacQueen, J. (1967). *Some Methods for Classification and Analysis of Multivariate Observations*
- مستندات کتابخانه scikit-learn
